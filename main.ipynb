{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the names.txt file from github\n",
    "#!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# 1. Check if the MPS backend is available\\nif torch.backends.mps.is_available():\\n    # 2. Set the default device to \\'mps\\'\\n    torch.set_default_device(\\'mps\\')\\n    print(\"Default device has been set to \\'mps\\' (Mac GPU)\")\\nelse:\\n    # Fallback to CPU if MPS is not available\\n    print(\"MPS not available. Default device remains \\'cpu\\'.\")'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 1. Check if the MPS backend is available\n",
    "if torch.backends.mps.is_available():\n",
    "    # 2. Set the default device to 'mps'\n",
    "    torch.set_default_device('mps')\n",
    "    print(\"Default device has been set to 'mps' (Mac GPU)\")\n",
    "else:\n",
    "    # Fallback to CPU if MPS is not available\n",
    "    print(\"MPS not available. Default device remains 'cpu'.\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default device has been set to 'cpu'\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_device('cpu')\n",
    "print(\"Default device has been set to 'cpu'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\n"
     ]
    }
   ],
   "source": [
    "#get all words from names.txt\n",
    "words = open('data/names.txt', 'r').read().splitlines()\n",
    "print(words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n",
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "#get all the unique characters in the words\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "print(chars)\n",
    "\n",
    "# create a mapping from characters to integers\n",
    "stoi = {ch:i+1 for i, ch in enumerate(chars)}\n",
    "itos = {i+1:ch for i, ch in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos[0] = '.'\n",
    "vocab_size = len(itos)\n",
    "print(stoi)\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182436, 1]) torch.Size([182436, 1])\n",
      "torch.Size([22908, 1]) torch.Size([22908, 1])\n",
      "torch.Size([22802, 1]) torch.Size([22802, 1])\n"
     ]
    }
   ],
   "source": [
    "block_size = 10\n",
    "\n",
    "#build the dataset\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    for word in words:\n",
    "        context = [0]\n",
    "        for ch in word + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            context = context[1:] + [ix]\n",
    "            Y.append(context)\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    \n",
    "    return (X, Y)\n",
    "def build_dataset_gpt(words):\n",
    "    data = []\n",
    "    for word in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in word:\n",
    "            ix = stoi[ch]\n",
    "            data.append(context)\n",
    "            context = context[1:] + [ix]\n",
    "    data = torch.tensor(data)\n",
    "    print(data.shape)\n",
    "    return data\n",
    "\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "random.shuffle(words)\n",
    "\n",
    "\n",
    "train_data, train_targets  = build_dataset(words[:n1])     # 80%\n",
    "val_data, val_targets = build_dataset(words[n1:n2])   # 10%\n",
    "test_data, test_targets  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "max_iters = 5000\n",
    "learning_rate = 1e-4\n",
    "n_embd = 35\n",
    "n_head = 5\n",
    "n_layer = 5\n",
    "n_input = block_size * n_embd\n",
    "n_output = vocab_size\n",
    "\n",
    "history_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    if split == 'train':\n",
    "        data = train_data\n",
    "        targets = train_targets\n",
    "    else:\n",
    "        data = val_data\n",
    "        targets = val_targets\n",
    "    ix = torch.randint(0, data.shape[0], (batch_size,))\n",
    "    x = data[ix]\n",
    "    y = targets[ix]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14],\n",
      "        [ 4],\n",
      "        [ 9],\n",
      "        [ 5],\n",
      "        [ 0]])\n",
      "tensor([[20],\n",
      "        [ 5],\n",
      "        [25],\n",
      "        [ 0],\n",
      "        [10]])\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch('train')\n",
    "print(x[:5])\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential model\n",
    "class Sequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "\n",
    "    def append(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "#Embedding layer\n",
    "class Embedding:\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.weight = torch.randn(num_embeddings, embedding_dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.out = self.weight[x]\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight]\n",
    "\n",
    "#Linear layer\n",
    "class Linear:\n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.fan_in = fan_in\n",
    "        self.fan_out = fan_out\n",
    "        self.weight = torch.randn(fan_in, fan_out)/fan_in**0.5 #kaiming initialization\n",
    "        self.bias = torch.zeros(fan_out) if bias else None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "#Tanh activation function\n",
    "class Tanh:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "#softmax activation function\n",
    "class Softmax:\n",
    "    def __init__(self, dim = 1):\n",
    "        self.dim = dim\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.softmax(x, dim=self.dim)\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "#ReLU activation function\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.relu(x)\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "#Flatten layer\n",
    "class Flatten:\n",
    "    def __init__(self, start_dim=1, end_dim=-1):\n",
    "        self.start_dim = start_dim\n",
    "        self.end_dim = end_dim\n",
    "    def __call__(self, x):\n",
    "        #(d_1, d_2, ..., d_n) -> (d_1, d_2*...*d_)\n",
    "        shape = list()\n",
    "        if self.end_dim == -1:\n",
    "            for i, dim in enumerate(x.shape):\n",
    "                if (i <= self.start_dim) or (len(shape) == 0):\n",
    "                    shape.append(dim)\n",
    "                else:\n",
    "                    shape[-1] *= dim\n",
    "        else:\n",
    "            for i, dim in enumerate(x.shape):\n",
    "                if (i <= self.start_dim) or (len(shape) == 0):\n",
    "                    shape.append(dim)\n",
    "                elif i > self.end_dim:\n",
    "                    shape.append(dim)\n",
    "                else:\n",
    "                    shape[-1] *= dim\n",
    "        self.out = x.view(shape)\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "#Vanila RNN layer\n",
    "class RNN:\n",
    "    def __init__(self, n_input, n_hidden):\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        #self.non_linearity = non_linearity\n",
    "        self.W_xh = torch.randn(n_input, n_hidden) / n_input**0.5 #kaiming initialization\n",
    "        self.W_hh = torch.randn(n_hidden, n_hidden) / n_hidden**0.5 #kaiming initialization\n",
    "        self.b_h = torch.zeros(n_hidden)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        #(N, L, H_in) -> (N, L, H_out)\n",
    "        #h_t -> (N, H_out)\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        h_t = torch.zeros(batch_size, self.n_hidden)\n",
    "        output = []\n",
    "        for i in range(seq_len):\n",
    "            h_t = torch.tanh(x[:, i, :] @ self.W_xh + h_t @ self.W_hh + self.b_h)\n",
    "            output.append(h_t)\n",
    "\n",
    "        self.h = torch.stack(output, dim=1)\n",
    "        return self.h\n",
    "    def parameters(self):\n",
    "        return [self.W_xh, self.W_hh, self.b_h]\n",
    "\n",
    "#LSTM layer\n",
    "class LSTM:\n",
    "    def __init__(self, n_input, n_hidden):\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.W_ii = torch.randn(n_input, n_hidden) / n_input**0.5 #kaiming initialization\n",
    "        self.W_hi = torch.randn(n_hidden, n_hidden) / n_hidden**0.5 #kaiming initialization\n",
    "        self.b_i = torch.zeros(n_hidden)\n",
    "        \n",
    "        self.W_if = torch.randn(n_input, n_hidden) / n_input**0.5 #kaiming initialization\n",
    "        self.W_hf = torch.randn(n_hidden, n_hidden) / n_hidden**0.5 #kaiming initialization\n",
    "        self.b_f = torch.zeros(n_hidden)\n",
    "        \n",
    "        self.W_ig = torch.randn(n_input, n_hidden) / n_input**0.5 #kaiming initialization\n",
    "        self.W_hg = torch.randn(n_hidden, n_hidden) / n_hidden**0.5 #kaiming initialization\n",
    "        self.b_g = torch.zeros(n_hidden)\n",
    "        \n",
    "        self.W_io = torch.randn(n_input, n_hidden) / n_input**0.5 #kaiming initialization\n",
    "        self.W_ho = torch.randn(n_hidden, n_hidden) / n_hidden**0.5 #kaiming initialization\n",
    "        self.b_o = torch.zeros(n_hidden)\n",
    "\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        #(N, L, H_in) -> (N, L, H_out)\n",
    "        #h_t -> (N, H_out)\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        h_t = torch.zeros(batch_size, self.n_hidden)\n",
    "        c_t = torch.zeros(batch_size, self.n_hidden)\n",
    "        output = []\n",
    "        for i in range(seq_len):\n",
    "            i_t = torch.sigmoid(x[:, i, :] @ self.W_ii + h_t @ self.W_hi + self.b_i)\n",
    "            f_t = torch.sigmoid(x[:, i, :] @ self.W_if + h_t @ self.W_hf + self.b_f)\n",
    "            g_t = torch.tanh(x[:, i, :] @ self.W_ig + h_t @ self.W_hg + self.b_g)\n",
    "            o_t = torch.sigmoid(x[:, i, :] @ self.W_io + h_t @ self.W_ho + self.b_o)\n",
    "            c_t = f_t * c_t + i_t * g_t\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "            output.append(h_t)\n",
    "        self.h = torch.stack(output, dim=1)\n",
    "        self.c = c_t\n",
    "        return self.h\n",
    "    def parameters(self):\n",
    "        return [self.W_ii, self.W_hi, self.b_i, self.W_if, self.W_hf, self.b_f, self.W_ig, self.W_hg, self.b_g, self.W_io, self.W_ho, self.b_o]\n",
    "\n",
    "#GRU layer\n",
    "class GRU:\n",
    "    def __init__(self, n_input, n_hidden):\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        \n",
    "        self.W_ir = torch.randn(n_input, n_hidden) / n_input**0.5 #kaiming initialization\n",
    "        self.W_hr = torch.randn(n_hidden, n_hidden) / n_hidden**0.5 #kaiming initialization\n",
    "        self.b_r = torch.zeros(n_hidden)\n",
    "        \n",
    "        self.W_iz = torch.randn(n_input, n_hidden) / n_input**0.5 #kaiming initialization\n",
    "        self.W_hz = torch.randn(n_hidden, n_hidden) / n_hidden**0.5 #kaiming initialization\n",
    "        self.b_z = torch.zeros(n_hidden)\n",
    "        \n",
    "        self.W_in = torch.randn(n_input, n_hidden) / n_input**0.5 #kaiming initialization\n",
    "        self.W_hn = torch.randn(n_hidden, n_hidden) / n_hidden**0.5 #kaiming initialization\n",
    "        self.b_in = torch.zeros(n_hidden)\n",
    "        self.b_hn = torch.zeros(n_hidden)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.W_ir, self.W_hr, self.b_r, self.W_iz, self.W_hz, self.b_z, self.W_in, self.W_hn, self.b_in, self.b_hn]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        h_t = torch.zeros(batch_size, self.n_hidden)\n",
    "        output = []\n",
    "        \n",
    "        for i in range(seq_len):\n",
    "            r_t = torch.sigmoid(x[:, i, :] @ self.W_ir + h_t @ self.W_hr + self.b_r)\n",
    "            z_t = torch.sigmoid(x[:, i, :] @ self.W_iz + h_t @ self.W_hz + self.b_z)\n",
    "            n_t = torch.tanh(x[:, i, :] @ self.W_in + self.b_in + r_t * (h_t @ self.W_hn + self.b_hn))\n",
    "            h_t = (1 - z_t) * n_t + z_t * h_t\n",
    "            output.append(h_t)\n",
    "        self.h = torch.stack(output, dim=1)\n",
    "        \n",
    "        return self.h\n",
    "\n",
    "#Batch normalization\n",
    "class BatchNorm1d:\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1, training=True):\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = training\n",
    "        self.running_mean = torch.zeros(num_features)\n",
    "        self.running_var = torch.ones(num_features)\n",
    "        self.gamma = torch.ones(num_features)\n",
    "        self.beta = torch.zeros(num_features)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        if self.training:\n",
    "            if x.ndim == 2:\n",
    "                dim = 0\n",
    "            elif x.ndim == 3:\n",
    "                dim = (0, 1)\n",
    "            x_mean = x.mean(dim=dim, keepdim=True)\n",
    "            x_var = x.var(dim=dim, keepdim=True)\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = self.momentum * self.running_mean + (1 - self.momentum) * x_mean\n",
    "                self.running_var = self.momentum * self.running_var + (1 - self.momentum) * x_var\n",
    "        else:\n",
    "            x_mean = self.running_mean\n",
    "            x_var = self.running_var\n",
    "        x_std = torch.sqrt(x_var + self.eps)\n",
    "        x_hat = (x - x_mean) / x_std\n",
    "        self.out = x_hat * self.gamma + self.beta\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "#Layer normalization\n",
    "class LayerNorm:\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        self.num_features = normalized_shape\n",
    "        self.eps = eps\n",
    "        self.gamma = torch.ones(normalized_shape)\n",
    "        self.beta = torch.zeros(normalized_shape)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        x_mean = x.mean(dim=-1, keepdim=True)\n",
    "        x_var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        self.out = (x - x_mean) / torch.sqrt(x_var + self.eps) * self.gamma + self.beta\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGD optimizer\n",
    "class SGD:\n",
    "    def __init__(self, parameters, lr=0.001, momentum=0):\n",
    "        self.parameters = parameters\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = [torch.zeros_like(p) for p in parameters]\n",
    "        #self.dampening = dampening\n",
    "        #self.weight_decay = weight_decay\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.parameters:\n",
    "            p.grad = None\n",
    "        \n",
    "    def step(self):\n",
    "        for (i, p) in enumerate(self.parameters):\n",
    "            if p.grad is not None:\n",
    "                self.v[i] = self.momentum * self.v[i] + (1 - self.momentum) * p.grad\n",
    "                p.data -= self.lr * self.v[i]\n",
    "\n",
    "#Adam optimizer\n",
    "class Adam:\n",
    "    def __init__(self, parameters, lr = 0.001, betas = (0.9, 0.999), eps = 1e-8):\n",
    "        self.parameters = parameters\n",
    "        self.lr = lr\n",
    "        self.betas = betas\n",
    "        self.eps = eps\n",
    "        self.m = [torch.zeros_like(p) for p in parameters]\n",
    "        self.v = [torch.zeros_like(p) for p in parameters]\n",
    "        self.t = 0\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        for p in self.parameters:\n",
    "            p.grad = None\n",
    "    \n",
    "    def step(self):\n",
    "        self.t += 1\n",
    "        for (i, p) in enumerate(self.parameters):\n",
    "            if p.grad is not None:\n",
    "                self.m[i] = self.betas[0] * self.m[i] + (1 - self.betas[0]) * p.grad\n",
    "                self.v[i] = self.betas[1] * self.v[i] + (1 - self.betas[1]) * p.grad**2\n",
    "                m_hat = self.m[i] / (1 - self.betas[0]**self.t)\n",
    "                v_hat = self.v[i] / (1 - self.betas[1]**self.t)\n",
    "                p.data -= self.lr * m_hat / (torch.sqrt(v_hat) + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Residual block\n",
    "class ResidualBlock():\n",
    "    def __init__(self, n_hidden):\n",
    "        self.linear1 = Linear(n_hidden, n_hidden, bias=False)\n",
    "        self.linear2 = Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.relu = ReLU()\n",
    "        self.batchnorm = BatchNorm1d(n_hidden)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        input = x\n",
    "        x = self.linear1(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return input + x #residual connection\n",
    "    def parameters(self):\n",
    "        return self.linear1.parameters() + self.linear2.parameters() + self.batchnorm.parameters()\n",
    "    \n",
    "#TakeLayer\n",
    "class TakeLayer:\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return x[:, self.index, :]\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "#SelfAttention layer\n",
    "class SelfAttention:\n",
    "    def __init__(self, n_embd, head_size):\n",
    "        self.n_embd = n_embd\n",
    "        self.head_size = head_size\n",
    "        self.query = Linear(n_embd, head_size, bias=False)\n",
    "        self.key = Linear(n_embd, head_size, bias=False)\n",
    "        self.value = Linear(n_embd, head_size, bias=False)\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.query.parameters() + self.key.parameters() + self.value.parameters()\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        #input shape: (N, L, H_in)\n",
    "        #output shape: (N, L, H_out)\n",
    "        N, L, _ = x.size()\n",
    "        H_out = self.head_size\n",
    "        q = self.query(x) #(N, L, H_out)\n",
    "        k = self.key(x) #(N, L, H_out)\n",
    "        v = self.value(x) #(N, L, H_out)\n",
    "        \n",
    "        wei = q @ k.transpose(-2, -1) * H_out**-0.5 #(N, L, L)\n",
    "        tril = torch.tril(torch.ones(L, L)) #(L, L)\n",
    "        wei = wei.masked_fill(tril == 0, float('-inf')) #(N, L, L)\n",
    "        wei = F.softmax(wei, dim=-1) #(N, L, L)\n",
    "        \n",
    "        out = wei @ v #(N, L, H_out)\n",
    "        return out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.query.parameters() + self.key.parameters() + self.value.parameters()\n",
    "\n",
    "#MultiHeadAttention layer\n",
    "class MultiHeadAttention:\n",
    "    def __init__(self, n_embd, head_size, n_heads):\n",
    "        self.n_embd = n_embd\n",
    "        self.head_size = head_size\n",
    "        self.n_heads = n_heads\n",
    "        self.heads = [SelfAttention(n_embd, head_size) for _ in range(n_heads)]\n",
    "        self.project = Linear(head_size * n_heads, n_embd)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [param for head in self.heads for param in head.parameters()] + self.project.parameters()\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        out = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        out = self.project(out)\n",
    "        return out\n",
    "    \n",
    "#FeedForward layer\n",
    "class FeedForward:\n",
    "    def __init__(self, n_embd):\n",
    "        self.n_embd = n_embd\n",
    "        self.net = Sequential(\n",
    "            [\n",
    "            Linear(n_embd, 4*n_embd, bias=True),\n",
    "            ReLU(),\n",
    "            Linear(4*n_embd, n_embd, bias=True)\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.net.parameters()\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "#ResidualTransformerBlock\n",
    "class ResidualTransformerBlock:\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        self.n_embd = n_embd\n",
    "        head_size = n_embd // n_head\n",
    "        self.n_head = n_head\n",
    "        self.attention = MultiHeadAttention(n_embd, head_size, n_head)\n",
    "        self.norm1 = LayerNorm(n_embd)\n",
    "        self.feedforward = FeedForward(n_embd)\n",
    "        self.norm2 = LayerNorm(n_embd)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.attention.parameters() + self.norm1.parameters() + self.norm2.parameters() + self.feedforward.parameters()\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = x + self.attention(self.norm1(x))\n",
    "        x = x + self.feedforward(self.norm2(x))\n",
    "        return x\n",
    "    \n",
    "#Token + position embedding\n",
    "class TokenEmbedding:\n",
    "    def __init__(self, vocab_size, n_embd):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_embd = n_embd\n",
    "        self.token_embedding_table = Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = Embedding(block_size, n_embd)\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.token_embedding_table.parameters() + self.position_embedding_table .parameters()\n",
    "    \n",
    "    def __call__(self, idx):\n",
    "        B, T = idx.shape\n",
    "        \n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T)) # (T,C)\n",
    "\n",
    "        return tok_emb + pos_emb\n",
    "    \n",
    "class GPT:\n",
    "    def __init__(self, vocab_size, n_embd, n_head, n_layer, block_size):\n",
    "        self.token_embedding = TokenEmbedding(vocab_size, n_embd)\n",
    "        self.lm_head = Linear(n_embd, vocab_size)\n",
    "        self.transformer_blocks = Sequential([ResidualTransformerBlock(n_embd, n_head) for _ in range(n_layer)])\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_embd = n_embd\n",
    "        self.n_head = n_head\n",
    "        self.n_layer = n_layer\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.token_embedding.parameters() + self.lm_head.parameters() + self.transformer_blocks.parameters()\n",
    "    \n",
    "    def __call__(self, idx, targets=None):\n",
    "        x = self.token_embedding(idx)\n",
    "        x = self.transformer_blocks(x)\n",
    "        x = self.lm_head(x)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = x.shape\n",
    "            x = x.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(x, targets)\n",
    "        return (x, loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model\n",
    "'''model = Sequential(\n",
    "    [TokenEmbedding(vocab_size, n_embd),\n",
    "    ResidualTransformerBlock(n_embd, n_head),\n",
    "    ResidualTransformerBlock(n_embd, n_head),\n",
    "    ResidualTransformerBlock(n_embd, n_head),\n",
    "    LayerNorm(n_embd),\n",
    "    Linear(n_embd, vocab_size, bias=True),\n",
    "    TakeLayer(-1),\n",
    "    ]\n",
    ")'''\n",
    "model = GPT(vocab_size, n_embd, n_head, n_layer, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.lr = learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, loss 7.697058200836182\n",
      "iter 1000, loss 1.2662808895111084\n",
      "iter 2000, loss 1.2664010524749756\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iters):\n\u001b[32m      3\u001b[39m     x_batch, y_batch = get_batch(\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     logits, loss = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m#backward pass\u001b[39;00m\n\u001b[32m      8\u001b[39m     optimizer.zero_grad()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 151\u001b[39m, in \u001b[36mGPT.__call__\u001b[39m\u001b[34m(self, idx, targets)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx, targets=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    150\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.token_embedding(idx)\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.lm_head(x)\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mSequential.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m         x = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mself\u001b[39m.out = x\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.out\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 112\u001b[39m, in \u001b[36mResidualTransformerBlock.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     x = x + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m.feedforward(\u001b[38;5;28mself\u001b[39m.norm2(x))\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mMultiHeadAttention.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     out = torch.cat([\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m head \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.heads], dim=-\u001b[32m1\u001b[39m)\n\u001b[32m     76\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.project(out)\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mSelfAttention.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     53\u001b[39m wei = wei.masked_fill(tril == \u001b[32m0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m-inf\u001b[39m\u001b[33m'\u001b[39m)) \u001b[38;5;66;03m#(N, L, L)\u001b[39;00m\n\u001b[32m     54\u001b[39m wei = F.softmax(wei, dim=-\u001b[32m1\u001b[39m) \u001b[38;5;66;03m#(N, L, L)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m out = \u001b[43mwei\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m \u001b[38;5;66;03m#(N, L, H_out)\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/makemoremore/venv/lib/python3.12/site-packages/torch/utils/_device.py:104\u001b[39m, in \u001b[36mDeviceContext.__torch_function__\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs.get(\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    103\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.device\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for iter in range(max_iters):\n",
    "    x_batch, y_batch = get_batch('train')\n",
    "    \n",
    "    logits, loss = model(x_batch, y_batch)\n",
    "\n",
    "    #backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    #update the parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    history_loss.append(loss.log10().item())\n",
    "        \n",
    "    if iter % 1000 == 0:\n",
    "        print(f\"iter {iter}, loss {loss.item()}\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"The for loop took {elapsed_time:.4f} seconds to run.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16810d0d0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(history_loss).view(-1, 1000).mean(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small batch:\n",
    "\n",
    "\n",
    "MPS time: 25.2170 seconds \n",
    "\n",
    "CPU time: 5.1533 seconds\n",
    "\n",
    "\n",
    "Big batch:\n",
    "\n",
    "MPS time: 39.9550 seconds \n",
    "\n",
    "CPU time: 26.8415 seconds\n",
    "\n",
    "\n",
    "The biggest batch (small loop):\n",
    "\n",
    "MPS time: 38.4508 seconds \n",
    "\n",
    "CPU time: 21.8074 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#model.layers[3].training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train loss\n",
    "logits, _ = model(train_data, None)\n",
    "loss = F.cross_entropy(logits[:, -1, :], train_targets[:, -1])\n",
    "print(f\"Train loss: {loss.item()}\")\n",
    "\n",
    "#validation\n",
    "logits, _ = model(val_data, None)\n",
    "loss = F.cross_entropy(logits[:, -1, :], val_targets[:, -1])\n",
    "print(f\"Validation loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD:\n",
    "\n",
    "Train loss: 2.062329053878784\n",
    "\n",
    "Validation loss: 2.1204097270965576\n",
    "\n",
    "Adam:\n",
    "\n",
    "1 hidden layer:\n",
    "\n",
    "Train loss: 2.0225372314453125\n",
    "\n",
    "Validation loss: 2.1021244525909424\n",
    "\n",
    "2 hidden layers:\n",
    "\n",
    "Train loss: 2.1282734870910645\n",
    "\n",
    "Validation loss: 2.15704607963562\n",
    "\n",
    "Residual layer:\n",
    "\n",
    "Train loss: 2.072701930999756\n",
    "\n",
    "Validation loss: 2.1089556217193604\n",
    "\n",
    "Vanila RNN:\n",
    "\n",
    "Train loss: 2.015709161758423\n",
    "\n",
    "Validation loss: 2.1081628799438477\n",
    "\n",
    "LSTM:\n",
    "\n",
    "Train loss: 1.98944091796875\n",
    "\n",
    "Validation loss: 2.0500173568725586\n",
    "\n",
    "GRU:\n",
    "\n",
    "Train loss: 1.834752082824707\n",
    "\n",
    "Validation loss: 2.0203657150268555\n",
    "\n",
    "1 Self attention:\n",
    "\n",
    "Train loss: 2.8630714416503906\n",
    "\n",
    "Validation loss: 2.865368127822876\n",
    "\n",
    "Multihead attention + FF:\n",
    "\n",
    "Train loss: 2.530355930328369\n",
    "\n",
    "Validation loss: 2.532259464263916\n",
    "\n",
    "Multihead attention + FF + LayerNorm:\n",
    "\n",
    "Train loss: 2.2954459190368652\n",
    "\n",
    "Validation loss: 2.304565906524658\n",
    "\n",
    "Multihead attention + FF + LayerNorm + Residual:\n",
    "\n",
    "Train loss: 2.268521547317505\n",
    "\n",
    "Validation loss: 2.272268533706665\n",
    "\n",
    "Multiple Multihead attention + FF + LayerNorm + Residual:\n",
    "\n",
    "Train loss: 2.203157663345337\n",
    "\n",
    "Validation loss: 2.218388080596924\n",
    "\n",
    "Everything from above + position embedding\n",
    "Train loss: 2.15106463432312\n",
    "\n",
    "Validation loss: 2.182623863220215\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zersay.\n",
      "natleli.\n",
      "belaredn.\n",
      "jishaseh.\n",
      "lynona.\n",
      "anann.\n",
      "aumarin.\n",
      "anaita.\n",
      "kynatii.\n",
      "riyann.\n",
      "yasahah.\n",
      "sexly.\n",
      "nelianga.\n",
      "eryda.\n",
      "zaten.\n",
      "tashni.\n",
      "animitoli.\n",
      "isvha.\n",
      "vihasfien.\n",
      "ronian.\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # forward pass the neural net\n",
    "      logits, _ = model(torch.tensor([context]))\n",
    "      logits = logits[0, -1, :]\n",
    "      probs = F.softmax(logits, dim=-1)\n",
    "      # sample from the distribution\n",
    "      ix = torch.multinomial(probs, num_samples=1).item()\n",
    "      # shift the context window and track the samples\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      # if we sample the special '.' token, break\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
