{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-19 20:59:54--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8001::154, 2606:50c0:8003::154, 2606:50c0:8002::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8001::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 228145 (223K) [text/plain]\n",
      "Saving to: ‘names.txt’\n",
      "\n",
      "names.txt           100%[===================>] 222.80K  --.-KB/s    in 0.05s   \n",
      "\n",
      "2025-06-19 20:59:55 (4.28 MB/s) - ‘names.txt’ saved [228145/228145]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download the names.txt file from github\n",
    "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default device has been set to 'mps' (Mac GPU)\n"
     ]
    }
   ],
   "source": [
    "# 1. Check if the MPS backend is available\n",
    "if torch.backends.mps.is_available():\n",
    "    # 2. Set the default device to 'mps'\n",
    "    torch.set_default_device('mps')\n",
    "    print(\"Default device has been set to 'mps' (Mac GPU)\")\n",
    "else:\n",
    "    # Fallback to CPU if MPS is not available\n",
    "    print(\"MPS not available. Default device remains 'cpu'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default device has been set to 'cpu'\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_device('cpu')\n",
    "print(\"Default device has been set to 'cpu'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\n"
     ]
    }
   ],
   "source": [
    "#get all words from names.txt\n",
    "words = open('data/names.txt', 'r').read().splitlines()\n",
    "print(words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n",
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "#get all the unique characters in the words\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "print(chars)\n",
    "\n",
    "# create a mapping from characters to integers\n",
    "stoi = {ch:i+1 for i, ch in enumerate(chars)}\n",
    "itos = {i+1:ch for i, ch in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos[0] = '.'\n",
    "vocab_size = len(itos)\n",
    "print(stoi)\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 3\n",
    "\n",
    "#build the dataset\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    for word in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in word:\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    \n",
    "    return (X, Y)\n",
    "\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Batch normalization\\nclass BatchNorm1d:\\n    def __init__(self, ):\\n        '"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sequential model\n",
    "class Sequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [layer.parameters() for layer in self.layers]\n",
    "\n",
    "    def append(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "#Embedding layer\n",
    "class Embedding:\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.weight = torch.randn(num_embeddings, embedding_dim)/num_embeddings**0.5\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.out = self.weight[x]\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight]\n",
    "\n",
    "#Linear layer\n",
    "class Linear:\n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.fan_in = fan_in\n",
    "        self.fan_out = fan_out\n",
    "        self.weight = torch.randn(fan_in, fan_out)/fan_in**0.5 #kaiming initialization\n",
    "        self.bias = torch.zeros(fan_out) if bias else None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight + self.bias\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return [self.weight, self.bias]\n",
    "\n",
    "#Tanh activation function\n",
    "class Tanh:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "\n",
    "#softmax activation function\n",
    "class Softmax:\n",
    "    def __init__(self, dim = 1):\n",
    "        self.dim = dim\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.softmax(x, dim=self.dim)\n",
    "        return self.out\n",
    "\n",
    "#ReLU activation function\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.relu(x)\n",
    "        return self.out\n",
    "\n",
    "'''#Batch normalization\n",
    "class BatchNorm1d:\n",
    "    def __init__(self, ):\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20000\n",
    "max_iters = 3000\n",
    "learning_rate = 1e-2\n",
    "n_embd = 10\n",
    "n_hidden = 10\n",
    "n_input = block_size * n_embd\n",
    "n_output = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model\n",
    "model = Sequential(\n",
    "    [Embedding(vocab_size, n_embd),\n",
    "    Linear(n_embd, n_hidden), Tanh(),\n",
    "    Linear(n_hidden, n_output)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model\n",
    "C = torch.randn(vocab_size, n_embd)\n",
    "w1 = torch.randn(n_input, n_hidden)\n",
    "w2 = torch.randn(n_hidden, n_output)\n",
    "b1 = torch.randn(n_hidden)\n",
    "b2 = torch.randn(n_output)\n",
    "\n",
    "parameters = [C, w1, w2, b1, b2]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, loss 6.442702770233154\n",
      "iter 100, loss 5.569154739379883\n",
      "iter 200, loss 5.18377161026001\n",
      "iter 300, loss 4.9155449867248535\n",
      "iter 400, loss 4.661125183105469\n",
      "iter 500, loss 4.5249199867248535\n",
      "iter 600, loss 4.326540470123291\n",
      "iter 700, loss 4.231530666351318\n",
      "iter 800, loss 4.1117377281188965\n",
      "iter 900, loss 3.9645440578460693\n",
      "iter 1000, loss 3.8666975498199463\n",
      "iter 1100, loss 3.8130598068237305\n",
      "iter 1200, loss 3.7475059032440186\n",
      "iter 1300, loss 3.6579160690307617\n",
      "iter 1400, loss 3.6058695316314697\n",
      "iter 1500, loss 3.5480453968048096\n",
      "iter 1600, loss 3.501758098602295\n",
      "iter 1700, loss 3.423393726348877\n",
      "iter 1800, loss 3.4103245735168457\n",
      "iter 1900, loss 3.3696296215057373\n",
      "iter 2000, loss 3.326004981994629\n",
      "iter 2100, loss 3.2905867099761963\n",
      "iter 2200, loss 3.2701127529144287\n",
      "iter 2300, loss 3.242154359817505\n",
      "iter 2400, loss 3.2077934741973877\n",
      "iter 2500, loss 3.2139241695404053\n",
      "iter 2600, loss 3.1442012786865234\n",
      "iter 2700, loss 3.1374199390411377\n",
      "iter 2800, loss 3.1186327934265137\n",
      "iter 2900, loss 3.1307473182678223\n",
      "The for loop took 21.8339 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for iter in range(max_iters):\n",
    "    idx = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "\n",
    "    x_batch = Xtr[idx]\n",
    "    y_batch = Ytr[idx]\n",
    "\n",
    "    #flatten the batch\n",
    "    x_batch = C[x_batch].view(x_batch.shape[0], -1)\n",
    "\n",
    "\n",
    "    #forward pass\n",
    "    h1 = x_batch @ w1 + b1\n",
    "    h1 = torch.tanh(h1)\n",
    "    h2 = h1 @ w2 + b2\n",
    "\n",
    "    #calculate the loss\n",
    "    loss = F.cross_entropy(h2, y_batch)\n",
    "\n",
    "    #backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    #update the parameters\n",
    "    for p in parameters:\n",
    "        p.data -= learning_rate * p.grad\n",
    "        \n",
    "    \n",
    "    if iter % 100 == 0:\n",
    "        print(f\"iter {iter}, loss {loss.item()}\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"The for loop took {elapsed_time:.4f} seconds to run.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small batch:\n",
    "\n",
    "\n",
    "MPS time: 25.2170 seconds \n",
    "\n",
    "CPU time: 5.1533 seconds\n",
    "\n",
    "\n",
    "Big batch:\n",
    "\n",
    "MPS time: 39.9550 seconds \n",
    "\n",
    "CPU time: 26.8415 seconds\n",
    "\n",
    "\n",
    "The biggest batch (small loop):\n",
    "\n",
    "MPS time: 38.4508 seconds \n",
    "\n",
    "CPU time: 21.8074 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
